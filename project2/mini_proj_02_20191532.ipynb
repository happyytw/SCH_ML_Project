{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "train = pd.read_csv('train.csv') \n",
    "#엑셀 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.274488</td>\n",
       "      <td>-0.017695</td>\n",
       "      <td>-0.109141</td>\n",
       "      <td>-0.605438</td>\n",
       "      <td>-0.510938</td>\n",
       "      <td>-0.604754</td>\n",
       "      <td>-0.630512</td>\n",
       "      <td>-0.526907</td>\n",
       "      <td>-0.606150</td>\n",
       "      <td>-0.468604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.307009</td>\n",
       "      <td>-0.625294</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>-0.005981</td>\n",
       "      <td>-0.489547</td>\n",
       "      <td>0.058593</td>\n",
       "      <td>-0.056515</td>\n",
       "      <td>17.413085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.070261</td>\n",
       "      <td>0.040811</td>\n",
       "      <td>0.056635</td>\n",
       "      <td>0.448734</td>\n",
       "      <td>0.502645</td>\n",
       "      <td>0.418687</td>\n",
       "      <td>0.424073</td>\n",
       "      <td>0.485942</td>\n",
       "      <td>0.414122</td>\n",
       "      <td>0.544547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321011</td>\n",
       "      <td>0.307584</td>\n",
       "      <td>0.336787</td>\n",
       "      <td>0.448306</td>\n",
       "      <td>0.608303</td>\n",
       "      <td>0.477975</td>\n",
       "      <td>0.511807</td>\n",
       "      <td>0.297480</td>\n",
       "      <td>0.279122</td>\n",
       "      <td>8.975143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.995357</td>\n",
       "      <td>-0.999765</td>\n",
       "      <td>-0.976580</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.262975</td>\n",
       "      <td>-0.024863</td>\n",
       "      <td>-0.120993</td>\n",
       "      <td>-0.992754</td>\n",
       "      <td>-0.978129</td>\n",
       "      <td>-0.980233</td>\n",
       "      <td>-0.993591</td>\n",
       "      <td>-0.978162</td>\n",
       "      <td>-0.980251</td>\n",
       "      <td>-0.936219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542602</td>\n",
       "      <td>-0.845573</td>\n",
       "      <td>-0.121527</td>\n",
       "      <td>-0.289549</td>\n",
       "      <td>-0.482273</td>\n",
       "      <td>-0.376341</td>\n",
       "      <td>-0.812065</td>\n",
       "      <td>-0.017885</td>\n",
       "      <td>-0.143414</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.277193</td>\n",
       "      <td>-0.017219</td>\n",
       "      <td>-0.108676</td>\n",
       "      <td>-0.946196</td>\n",
       "      <td>-0.851897</td>\n",
       "      <td>-0.859365</td>\n",
       "      <td>-0.950709</td>\n",
       "      <td>-0.857328</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.881637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.343685</td>\n",
       "      <td>-0.711692</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>-0.709417</td>\n",
       "      <td>0.182071</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.288461</td>\n",
       "      <td>-0.010783</td>\n",
       "      <td>-0.097794</td>\n",
       "      <td>-0.242813</td>\n",
       "      <td>-0.034231</td>\n",
       "      <td>-0.262415</td>\n",
       "      <td>-0.292680</td>\n",
       "      <td>-0.066701</td>\n",
       "      <td>-0.265671</td>\n",
       "      <td>-0.017129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126979</td>\n",
       "      <td>-0.503878</td>\n",
       "      <td>0.150865</td>\n",
       "      <td>0.292861</td>\n",
       "      <td>0.506187</td>\n",
       "      <td>0.359368</td>\n",
       "      <td>-0.509079</td>\n",
       "      <td>0.248353</td>\n",
       "      <td>0.107659</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989538</td>\n",
       "      <td>0.956845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998702</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \\\n",
       "count        7352.000000        7352.000000        7352.000000   \n",
       "mean            0.274488          -0.017695          -0.109141   \n",
       "std             0.070261           0.040811           0.056635   \n",
       "min            -1.000000          -1.000000          -1.000000   \n",
       "25%             0.262975          -0.024863          -0.120993   \n",
       "50%             0.277193          -0.017219          -0.108676   \n",
       "75%             0.288461          -0.010783          -0.097794   \n",
       "max             1.000000           1.000000           1.000000   \n",
       "\n",
       "       tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  \\\n",
       "count       7352.000000       7352.000000       7352.000000       7352.000000   \n",
       "mean          -0.605438         -0.510938         -0.604754         -0.630512   \n",
       "std            0.448734          0.502645          0.418687          0.424073   \n",
       "min           -1.000000         -0.999873         -1.000000         -1.000000   \n",
       "25%           -0.992754         -0.978129         -0.980233         -0.993591   \n",
       "50%           -0.946196         -0.851897         -0.859365         -0.950709   \n",
       "75%           -0.242813         -0.034231         -0.262415         -0.292680   \n",
       "max            1.000000          0.916238          1.000000          1.000000   \n",
       "\n",
       "       tBodyAcc-mad()-Y  tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  \\\n",
       "count       7352.000000       7352.000000       7352.000000  ...   \n",
       "mean          -0.526907         -0.606150         -0.468604  ...   \n",
       "std            0.485942          0.414122          0.544547  ...   \n",
       "min           -1.000000         -1.000000         -1.000000  ...   \n",
       "25%           -0.978162         -0.980251         -0.936219  ...   \n",
       "50%           -0.857328         -0.857143         -0.881637  ...   \n",
       "75%           -0.066701         -0.265671         -0.017129  ...   \n",
       "max            0.967664          1.000000          1.000000  ...   \n",
       "\n",
       "       fBodyBodyGyroJerkMag-skewness()  fBodyBodyGyroJerkMag-kurtosis()  \\\n",
       "count                      7352.000000                      7352.000000   \n",
       "mean                         -0.307009                        -0.625294   \n",
       "std                           0.321011                         0.307584   \n",
       "min                          -0.995357                        -0.999765   \n",
       "25%                          -0.542602                        -0.845573   \n",
       "50%                          -0.343685                        -0.711692   \n",
       "75%                          -0.126979                        -0.503878   \n",
       "max                           0.989538                         0.956845   \n",
       "\n",
       "       angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "count                  7352.000000                           7352.000000   \n",
       "mean                      0.008684                              0.002186   \n",
       "std                       0.336787                              0.448306   \n",
       "min                      -0.976580                             -1.000000   \n",
       "25%                      -0.121527                             -0.289549   \n",
       "50%                       0.009509                              0.008943   \n",
       "75%                       0.150865                              0.292861   \n",
       "max                       1.000000                              1.000000   \n",
       "\n",
       "       angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \\\n",
       "count                       7352.000000                           7352.000000   \n",
       "mean                           0.008726                             -0.005981   \n",
       "std                            0.608303                              0.477975   \n",
       "min                           -1.000000                             -1.000000   \n",
       "25%                           -0.482273                             -0.376341   \n",
       "50%                            0.008735                             -0.000368   \n",
       "75%                            0.506187                              0.359368   \n",
       "max                            0.998702                              0.996078   \n",
       "\n",
       "       angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  \\\n",
       "count           7352.000000           7352.000000           7352.000000   \n",
       "mean              -0.489547              0.058593             -0.056515   \n",
       "std                0.511807              0.297480              0.279122   \n",
       "min               -1.000000             -1.000000             -1.000000   \n",
       "25%               -0.812065             -0.017885             -0.143414   \n",
       "50%               -0.709417              0.182071              0.003181   \n",
       "75%               -0.509079              0.248353              0.107659   \n",
       "max                1.000000              0.478157              1.000000   \n",
       "\n",
       "           subject  \n",
       "count  7352.000000  \n",
       "mean     17.413085  \n",
       "std       8.975143  \n",
       "min       1.000000  \n",
       "25%       8.000000  \n",
       "50%      19.000000  \n",
       "75%      26.000000  \n",
       "max      30.000000  \n",
       "\n",
       "[8 rows x 562 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_data = train.drop(\"Activity\", axis=1)\n",
    "train_data = train_data.drop(\"subject\", axis=1)\n",
    "train_target = label_encoder.fit_transform(train[\"Activity\"].copy())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data.astype(np.float32))\n",
    "\n",
    "\n",
    "\n",
    "# 테스트 데이터\n",
    "# test_data = test.drop(\"Activity\", axis=1)\n",
    "# test_data = test_data.drop(\"subject\", axis=1)\n",
    "# test_target = label_encoder.transform(test[\"Activity\"].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-meanFreq()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "      <td>7352.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.274488</td>\n",
       "      <td>-0.017695</td>\n",
       "      <td>-0.109141</td>\n",
       "      <td>-0.605438</td>\n",
       "      <td>-0.510938</td>\n",
       "      <td>-0.604754</td>\n",
       "      <td>-0.630512</td>\n",
       "      <td>-0.526907</td>\n",
       "      <td>-0.606150</td>\n",
       "      <td>-0.468604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125293</td>\n",
       "      <td>-0.307009</td>\n",
       "      <td>-0.625294</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>-0.005981</td>\n",
       "      <td>-0.489547</td>\n",
       "      <td>0.058593</td>\n",
       "      <td>-0.056515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.070261</td>\n",
       "      <td>0.040811</td>\n",
       "      <td>0.056635</td>\n",
       "      <td>0.448734</td>\n",
       "      <td>0.502645</td>\n",
       "      <td>0.418687</td>\n",
       "      <td>0.424073</td>\n",
       "      <td>0.485942</td>\n",
       "      <td>0.414122</td>\n",
       "      <td>0.544547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250994</td>\n",
       "      <td>0.321011</td>\n",
       "      <td>0.307584</td>\n",
       "      <td>0.336787</td>\n",
       "      <td>0.448306</td>\n",
       "      <td>0.608303</td>\n",
       "      <td>0.477975</td>\n",
       "      <td>0.511807</td>\n",
       "      <td>0.297480</td>\n",
       "      <td>0.279122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.999873</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.995357</td>\n",
       "      <td>-0.999765</td>\n",
       "      <td>-0.976580</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.262975</td>\n",
       "      <td>-0.024863</td>\n",
       "      <td>-0.120993</td>\n",
       "      <td>-0.992754</td>\n",
       "      <td>-0.978129</td>\n",
       "      <td>-0.980233</td>\n",
       "      <td>-0.993591</td>\n",
       "      <td>-0.978162</td>\n",
       "      <td>-0.980251</td>\n",
       "      <td>-0.936219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023692</td>\n",
       "      <td>-0.542602</td>\n",
       "      <td>-0.845573</td>\n",
       "      <td>-0.121527</td>\n",
       "      <td>-0.289549</td>\n",
       "      <td>-0.482273</td>\n",
       "      <td>-0.376341</td>\n",
       "      <td>-0.812065</td>\n",
       "      <td>-0.017885</td>\n",
       "      <td>-0.143414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.277193</td>\n",
       "      <td>-0.017219</td>\n",
       "      <td>-0.108676</td>\n",
       "      <td>-0.946196</td>\n",
       "      <td>-0.851897</td>\n",
       "      <td>-0.859365</td>\n",
       "      <td>-0.950709</td>\n",
       "      <td>-0.857328</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.881637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>-0.343685</td>\n",
       "      <td>-0.711692</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>0.008735</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>-0.709417</td>\n",
       "      <td>0.182071</td>\n",
       "      <td>0.003181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.288461</td>\n",
       "      <td>-0.010783</td>\n",
       "      <td>-0.097794</td>\n",
       "      <td>-0.242813</td>\n",
       "      <td>-0.034231</td>\n",
       "      <td>-0.262415</td>\n",
       "      <td>-0.292680</td>\n",
       "      <td>-0.066701</td>\n",
       "      <td>-0.265671</td>\n",
       "      <td>-0.017129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289096</td>\n",
       "      <td>-0.126979</td>\n",
       "      <td>-0.503878</td>\n",
       "      <td>0.150865</td>\n",
       "      <td>0.292861</td>\n",
       "      <td>0.506187</td>\n",
       "      <td>0.359368</td>\n",
       "      <td>-0.509079</td>\n",
       "      <td>0.248353</td>\n",
       "      <td>0.107659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946700</td>\n",
       "      <td>0.989538</td>\n",
       "      <td>0.956845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998702</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.478157</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  \\\n",
       "count        7352.000000        7352.000000        7352.000000   \n",
       "mean            0.274488          -0.017695          -0.109141   \n",
       "std             0.070261           0.040811           0.056635   \n",
       "min            -1.000000          -1.000000          -1.000000   \n",
       "25%             0.262975          -0.024863          -0.120993   \n",
       "50%             0.277193          -0.017219          -0.108676   \n",
       "75%             0.288461          -0.010783          -0.097794   \n",
       "max             1.000000           1.000000           1.000000   \n",
       "\n",
       "       tBodyAcc-std()-X  tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  \\\n",
       "count       7352.000000       7352.000000       7352.000000       7352.000000   \n",
       "mean          -0.605438         -0.510938         -0.604754         -0.630512   \n",
       "std            0.448734          0.502645          0.418687          0.424073   \n",
       "min           -1.000000         -0.999873         -1.000000         -1.000000   \n",
       "25%           -0.992754         -0.978129         -0.980233         -0.993591   \n",
       "50%           -0.946196         -0.851897         -0.859365         -0.950709   \n",
       "75%           -0.242813         -0.034231         -0.262415         -0.292680   \n",
       "max            1.000000          0.916238          1.000000          1.000000   \n",
       "\n",
       "       tBodyAcc-mad()-Y  tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  \\\n",
       "count       7352.000000       7352.000000       7352.000000  ...   \n",
       "mean          -0.526907         -0.606150         -0.468604  ...   \n",
       "std            0.485942          0.414122          0.544547  ...   \n",
       "min           -1.000000         -1.000000         -1.000000  ...   \n",
       "25%           -0.978162         -0.980251         -0.936219  ...   \n",
       "50%           -0.857328         -0.857143         -0.881637  ...   \n",
       "75%           -0.066701         -0.265671         -0.017129  ...   \n",
       "max            0.967664          1.000000          1.000000  ...   \n",
       "\n",
       "       fBodyBodyGyroJerkMag-meanFreq()  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "count                      7352.000000                      7352.000000   \n",
       "mean                          0.125293                        -0.307009   \n",
       "std                           0.250994                         0.321011   \n",
       "min                          -1.000000                        -0.995357   \n",
       "25%                          -0.023692                        -0.542602   \n",
       "50%                           0.134000                        -0.343685   \n",
       "75%                           0.289096                        -0.126979   \n",
       "max                           0.946700                         0.989538   \n",
       "\n",
       "       fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "count                      7352.000000                  7352.000000   \n",
       "mean                         -0.625294                     0.008684   \n",
       "std                           0.307584                     0.336787   \n",
       "min                          -0.999765                    -0.976580   \n",
       "25%                          -0.845573                    -0.121527   \n",
       "50%                          -0.711692                     0.009509   \n",
       "75%                          -0.503878                     0.150865   \n",
       "max                           0.956845                     1.000000   \n",
       "\n",
       "       angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "count                           7352.000000                       7352.000000   \n",
       "mean                               0.002186                          0.008726   \n",
       "std                                0.448306                          0.608303   \n",
       "min                               -1.000000                         -1.000000   \n",
       "25%                               -0.289549                         -0.482273   \n",
       "50%                                0.008943                          0.008735   \n",
       "75%                                0.292861                          0.506187   \n",
       "max                                1.000000                          0.998702   \n",
       "\n",
       "       angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "count                           7352.000000           7352.000000   \n",
       "mean                              -0.005981             -0.489547   \n",
       "std                                0.477975              0.511807   \n",
       "min                               -1.000000             -1.000000   \n",
       "25%                               -0.376341             -0.812065   \n",
       "50%                               -0.000368             -0.709417   \n",
       "75%                                0.359368             -0.509079   \n",
       "max                                0.996078              1.000000   \n",
       "\n",
       "       angle(Y,gravityMean)  angle(Z,gravityMean)  \n",
       "count           7352.000000           7352.000000  \n",
       "mean               0.058593             -0.056515  \n",
       "std                0.297480              0.279122  \n",
       "min               -1.000000             -1.000000  \n",
       "25%               -0.017885             -0.143414  \n",
       "50%                0.182071              0.003181  \n",
       "75%                0.248353              0.107659  \n",
       "max                0.478157              1.000000  \n",
       "\n",
       "[8 rows x 561 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/76/nhbbpw0168g4pxc5wlf6ns2m0000gn/T/ipykernel_6816/3056656915.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  corr_matrix = train.corr()\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = train.corr()\n",
    "train_data = train.drop(\"Activity\", axis=1) # drop labels for training set\n",
    "train_data = train_data.drop(\"subject\", axis=1) # 필요없어 보여서 삭제\n",
    "train_target= train[\"Activity\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5447493345164153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create an instance of AdaBoostClassifier with desired parameters\n",
    "adaboost_clf = AdaBoostClassifier(\n",
    "    algorithm='SAMME.R', base_estimator=None,\n",
    "    learning_rate=1.0, n_estimators=50,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "adaboost_clf.fit(train_data.values, train_target)\n",
    "\n",
    "# Use cross_val_score with the new model\n",
    "cross_val_scores = cross_val_score(adaboost_clf, train_data.values, train_target, cv=10, scoring=\"accuracy\")\n",
    "print(f\"{cross_val_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8588187666370896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create an instance of DecisionTreeClassifier with desired parameters\n",
    "dt_clf = DecisionTreeClassifier(\n",
    "    ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "    max_depth=None, max_features=None, max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0, min_samples_leaf=1,\n",
    "    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "    random_state=123, splitter='best'\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "dt_clf.fit(train_data.values, train_target)\n",
    "\n",
    "# Use cross_val_score with the new model\n",
    "cross_val_scores = cross_val_score(dt_clf, train_data.values, train_target, cv=10, scoring=\"accuracy\")\n",
    "print(f\"{cross_val_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.931997744750074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create an instance of RandomForestClassifier with desired parameters\n",
    "rf_clf = RandomForestClassifier(\n",
    "    bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "    criterion='gini', max_depth=None, max_features='sqrt',\n",
    "    max_leaf_nodes=None, max_samples=None,\n",
    "    min_impurity_decrease=0.0, min_samples_leaf=1,\n",
    "    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100, n_jobs=-1, oob_score=False,\n",
    "    random_state=123, verbose=0, warm_start=False\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_clf.fit(train_data.values, train_target)\n",
    "\n",
    "# Use cross_val_score with the new model\n",
    "cross_val_scores = cross_val_score(rf_clf, train_data.values, train_target, cv=10, scoring=\"accuracy\")\n",
    "print(f\"{cross_val_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9341709183673469\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create an instance of SGDClassifier with desired parameters\n",
    "sgd_clf = SGDClassifier(\n",
    "    alpha=0.0001, average=False, class_weight=None,\n",
    "    early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,\n",
    "    l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
    "    max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
    "    power_t=0.5, random_state=123, shuffle=True, tol=0.001,\n",
    "    validation_fraction=0.1, verbose=0, warm_start=False\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "sgd_clf.fit(train_data.values, train_target)\n",
    "\n",
    "# Use cross_val_score with the new model\n",
    "cross_val_scores = cross_val_score(sgd_clf, train_data.values, train_target, cv=10, scoring=\"accuracy\")\n",
    "print(f\"{cross_val_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9477754362614611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taewonyoon/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create an instance of LogisticRegression with desired parameters\n",
    "logistic_reg_clf = LogisticRegression(\n",
    "    C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "    intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
    "    multi_class='auto', n_jobs=None, penalty='l2',\n",
    "    random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "    warm_start=False\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "logistic_reg_clf.fit(train_data.values, train_target)\n",
    "\n",
    "# Use cross_val_score with the new model\n",
    "cross_val_scores = cross_val_score(logistic_reg_clf, train_data.values, train_target, cv=10, scoring=\"accuracy\")\n",
    "print(f\"{cross_val_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9355351597160604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# ExtraTreesClassifier의 매개변수 설정\n",
    "extra_trees_params = {\n",
    "    'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None,\n",
    "    'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt',\n",
    "    'max_leaf_nodes': None, 'max_samples': None,\n",
    "    'min_impurity_decrease': 0.0, 'min_samples_leaf': 1,\n",
    "    'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0,\n",
    "    'n_estimators': 100, 'n_jobs': -1, 'oob_score': False,\n",
    "    'random_state': 123, 'verbose': 0, 'warm_start': False\n",
    "}\n",
    "\n",
    "# ExtraTreesClassifier 생성\n",
    "extra_trees_classifier = ExtraTreesClassifier(**extra_trees_params)\n",
    "\n",
    "# 모델을 훈련 데이터에 맞춤\n",
    "extra_trees_classifier.fit(train_data.values, train_target)\n",
    "\n",
    "# cross_val_score를 사용하여 모델 성능 평가\n",
    "cross_val_scores = cross_val_score(extra_trees_classifier, train_data.values, train_target, cv=10, scoring=\"accuracy\")\n",
    "print(f\"{cross_val_scores.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 좋았던 모델들로 앙상블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 데이터만 섞어도 성능 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 점수: [0.99184783 0.98913043 0.9877551  0.99183673 0.98639456 0.98911565\n",
      " 0.99183673 0.98367347 0.9877551  0.98503401]\n",
      "교차 검증 평균: 0.9884379621413784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 1\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.permutation(len(train_data_scaled))\n",
    "shuffled_train_data = train_data_scaled[shuffled_indices]\n",
    "shuffled_indices_train_target = train_target[shuffled_indices]\n",
    "\n",
    "# 모델 초기화\n",
    "logistic_regression_classifier = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "bagging_classifier = BaggingClassifier(\n",
    "    ExtraTreesClassifier(random_state=0, n_jobs=-1), bootstrap=False, random_state=42)\n",
    "svm_classifier = SVC(gamma='auto', probability=True, random_state=0, kernel=\"linear\")\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('lr', logistic_regression_classifier), ('rf', bagging_classifier), ('svc', svm_classifier)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 교차 검증 수행\n",
    "cross_val_scores = cross_val_score(voting_classifier, shuffled_train_data, shuffled_indices_train_target, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"교차 검증 점수: {cross_val_scores}\")\n",
    "print(f\"교차 검증 평균: {np.mean(cross_val_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 점수: [0.98777174 0.98097826 0.99047619 0.99047619 0.99319728 0.99183673\n",
      " 0.99591837 0.98639456 0.99047619 0.99319728]\n",
      "교차 검증 평균: 0.9900722789115646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# 기존 시드 변경\n",
    "seed = 21401\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.permutation(len(train_data))\n",
    "shuffled_train_data = train_data.values[shuffled_indices]\n",
    "shuffled_indices_train_target = train_target[shuffled_indices]\n",
    "\n",
    "# 모델 초기화\n",
    "logistic_regression_classifier = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "bagging_classifier = BaggingClassifier(\n",
    "    ExtraTreesClassifier(random_state=0, n_jobs=-1), bootstrap=False, random_state=42)\n",
    "svm_classifier = SVC(gamma='auto', probability=True, random_state=0, kernel=\"linear\")\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('lr', logistic_regression_classifier), ('rf', bagging_classifier), ('svc', svm_classifier)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 교차 검증 수행\n",
    "cross_val_scores = cross_val_score(voting_classifier, shuffled_train_data, shuffled_indices_train_target, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"교차 검증 점수: {cross_val_scores}\")\n",
    "print(f\"교차 검증 평균: {np.mean(cross_val_scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시드 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.99048913 0.98369565 0.99047619 0.99047619 0.99455782 0.99047619\n",
      " 0.99591837 0.99047619 0.98911565 0.99319728]\n",
      "Cross Validation Mean is 0.9908878660159715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# 기존 시드 변경\n",
    "seed = 21401\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.permutation(len(train_data))\n",
    "shuffled_train_data = train_data.values[shuffled_indices]\n",
    "shuffled_indices_train_target = train_target[shuffled_indices]\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "bag_clf = BaggingClassifier(\n",
    "    RandomForestClassifier(random_state=0, n_jobs=-1), bootstrap=False, random_state=42)\n",
    "svm_clf = SVC(gamma='auto', probability=True, random_state=0, kernel=\"linear\")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', bag_clf), ('svc', svm_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "    # 교차 검증 수행\n",
    "cross_val_scores = cross_val_score(voting_clf, shuffled_train_data, shuffled_indices_train_target, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Cross Validation Scores: {cross_val_scores}\")\n",
    "print(f\"Cross Validation Mean is {np.mean(cross_val_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배깅안에 랜포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.99048913 0.98369565 0.99047619 0.99047619 0.99455782 0.99047619\n",
      " 0.99591837 0.99047619 0.98911565 0.99319728]\n",
      "Cross Validation Mean is 0.9908878660159715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# 기본 시드 설정\n",
    "seed = 21401\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.permutation(len(train_data))\n",
    "shuffled_train_data = train_data.values[shuffled_indices]\n",
    "shuffled_indices_train_target = train_target[shuffled_indices]\n",
    "\n",
    "# 모델 초기화\n",
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=0)\n",
    "rf_clf = RandomForestClassifier(n_estimators=115, max_depth=15, random_state=0, n_jobs=-1)\n",
    "bag_clf = BaggingClassifier(\n",
    "    RandomForestClassifier(random_state=0, n_jobs=-1), bootstrap=False, random_state=42)\n",
    "svm_clf = SVC(gamma='auto', probability=True, random_state=0, kernel=\"linear\")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', bag_clf), ('svc', svm_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "    # 교차 검증 수행\n",
    "cross_val_scores = cross_val_score(voting_clf, shuffled_train_data, shuffled_indices_train_target, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Cross Validation Scores: {cross_val_scores}\")\n",
    "print(f\"Cross Validation Mean is {np.mean(cross_val_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.98641304 0.98233696 0.99047619 0.99047619 0.99183673 0.99047619\n",
      " 0.99455782 0.98367347 0.99183673 0.99183673]\n",
      "Cross Validation Mean is 0.9893920068027212\n",
      "Cross Validation Scores: [0.98641304 0.98233696 0.99047619 0.99047619 0.99183673 0.99047619\n",
      " 0.99455782 0.98367347 0.99183673 0.99183673]\n",
      "Cross Validation Mean is 0.9893920068027212\n",
      "Cross Validation Scores: [0.98641304 0.98233696 0.99047619 0.99047619 0.99183673 0.99047619\n",
      " 0.99455782 0.98367347 0.99183673 0.99183673]\n",
      "Cross Validation Mean is 0.9893920068027212\n",
      "Cross Validation Scores: [0.98641304 0.98233696 0.99047619 0.99047619 0.99183673 0.99047619\n",
      " 0.99455782 0.98367347 0.99183673 0.99183673]\n",
      "Cross Validation Mean is 0.9893920068027212\n",
      "Cross Validation Scores: [0.98641304 0.98233696 0.99047619 0.99047619 0.99183673 0.99047619\n",
      " 0.99455782 0.98367347 0.99183673 0.99183673]\n",
      "Cross Validation Mean is 0.9893920068027212\n",
      "Cross Validation Scores: [0.98641304 0.98233696 0.99047619 0.99047619 0.99183673 0.99047619\n",
      " 0.99455782 0.98367347 0.99183673 0.99183673]\n",
      "Cross Validation Mean is 0.9893920068027212\n",
      "Cross Validation Scores: [0.98641304 0.98233696 0.99047619 0.99047619 0.99183673 0.99047619\n",
      " 0.99455782 0.98367347 0.99183673 0.99183673]\n",
      "Cross Validation Mean is 0.9893920068027212\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import VotingClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# import numpy as np\n",
    "\n",
    "# # 기본 시드 설정\n",
    "# seed = 21401\n",
    "\n",
    "# # 데이터 섞기\n",
    "# np.random.seed(seed)\n",
    "# shuffled_indices = np.random.permutation(len(train_data))\n",
    "# shuffled_train_data = train_data.iloc[shuffled_indices]\n",
    "# shuffled_indices_train_target = train_target.iloc[shuffled_indices]\n",
    "\n",
    "# for i in range(25, 32):\n",
    "#     # 모델 초기화\n",
    "#     logistic_regression_classifier = LogisticRegression(solver=\"liblinear\", random_state=12300)\n",
    "#     random_forest_classifier = RandomForestClassifier(bootstrap=False, n_estimators=120, max_depth=i, random_state=9636, n_jobs=-1)\n",
    "#     svm_classifier = SVC(C=1, gamma='auto', probability=True, random_state=246, kernel=\"linear\")\n",
    "\n",
    "#     # Bagging Classifier를 초기화하고 base_estimator에 RandomForestClassifier를 지정\n",
    "#     bagging_classifier = BaggingClassifier(\n",
    "#         base_estimator=random_forest_classifier, bootstrap=True, random_state=42, n_jobs=-1\n",
    "#     )\n",
    "\n",
    "#     voting_classifier = VotingClassifier(\n",
    "#         estimators=[('lr', logistic_regression_classifier), ('rf', bagging_classifier), ('svc', svm_classifier)],\n",
    "#         voting='soft'\n",
    "#     )\n",
    "\n",
    "#     # 교차 검증 수행\n",
    "#     cross_val_scores = cross_val_score(voting_classifier, shuffled_train_data, shuffled_indices_train_target, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "#     print(f\"For max_depth={i}\")\n",
    "#     print(f\"Cross Validation Scores: {cross_val_scores}\")\n",
    "#     print(f\"Cross Validation Mean is {np.mean(cross_val_scores)}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.99048913 0.98505435 0.99183673 0.99183673 0.99455782 0.99183673\n",
      " 0.99591837 0.99047619 0.99047619 0.99319728]\n",
      "Cross Validation Mean is 0.9915679532682639\n"
     ]
    }
   ],
   "source": [
    "# 시드 설정하기\n",
    "seed = 21401\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.permutation(len(train_data))\n",
    "shuffled_train_data = train_data.values[shuffled_indices]\n",
    "shuffled_train_target = train_target[shuffled_indices]\n",
    "\n",
    "# 모델 초기화\n",
    "logistic_regression_classifier = LogisticRegression(solver=\"liblinear\", random_state=12300)\n",
    "random_forest_classifier = RandomForestClassifier(bootstrap=False, n_estimators=120, max_depth=30, random_state=9636, n_jobs=-1)\n",
    "svm_classifier = SVC(C=1, gamma='auto', probability=True, random_state=246, kernel=\"linear\")\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('lr', logistic_regression_classifier), ('rf', random_forest_classifier), ('svc', svm_classifier)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 교차 검증 수행\n",
    "cross_val_scores = cross_val_score(voting_classifier, shuffled_train_data, shuffled_train_target, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Cross Validation Scores: {cross_val_scores}\")\n",
    "print(f\"Cross Validation Mean is {np.mean(cross_val_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.99184783 0.98777174 0.99591837 0.99047619 0.98639456 0.98367347\n",
      " 0.98503401 0.99455782 0.99183673 0.99591837]\n",
      "Cross Validation Mean is 0.9903429089026915\n"
     ]
    }
   ],
   "source": [
    "# 시드 설정하기\n",
    "seed = 20000\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.permutation(len(train_data))\n",
    "shuffled_train_data = train_data.values[shuffled_indices]\n",
    "shuffled_train_target = train_target[shuffled_indices]\n",
    "\n",
    "svm_classifier = SVC(C=1, gamma='auto', probability=True, random_state=246, kernel=\"linear\")\n",
    "random_forest_classifier = RandomForestClassifier(bootstrap=False, n_estimators=120, max_depth=30, random_state=9636, n_jobs=-1)\n",
    "logistic_regression_classifier = LogisticRegression(solver=\"liblinear\", random_state=12300)\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('lr', logistic_regression_classifier), ('rf', random_forest_classifier), ('svc', svm_classifier)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 교차 검증 수행\n",
    "cross_val_scores = cross_val_score(voting_classifier, shuffled_train_data, shuffled_train_target, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Cross Validation Scores: {cross_val_scores}\")\n",
    "print(f\"Cross Validation Mean is {np.mean(cross_val_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.99320652 0.99456522 0.99727891 0.9877551  0.98367347 0.99047619\n",
      " 0.98367347 0.99047619 0.99727891 0.98911565]\n",
      "Cross Validation Mean is 0.9907499630286898\n"
     ]
    }
   ],
   "source": [
    "# 시드 설정하기\n",
    "seed = 90068\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.permutation(len(train_data))\n",
    "shuffled_train_data = train_data.values[shuffled_indices]\n",
    "shuffled_train_target = train_target[shuffled_indices]\n",
    "\n",
    "# 모델 초기화\n",
    "logistic_regression_classifier = LogisticRegression(solver=\"liblinear\", random_state=12300)\n",
    "random_forest_classifier = RandomForestClassifier(bootstrap=False, n_estimators=120, max_depth=30, random_state=9636, n_jobs=-1)\n",
    "svm_classifier = SVC(C=1, gamma='auto', probability=True, random_state=246, kernel=\"linear\")\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('lr', logistic_regression_classifier), ('rf', random_forest_classifier), ('svc', svm_classifier)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 교차 검증 수행\n",
    "cross_val_scores = cross_val_score(voting_classifier, shuffled_train_data, shuffled_train_target, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Cross Validation Scores: {cross_val_scores}\")\n",
    "print(f\"Cross Validation Mean is {np.mean(cross_val_scores)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Scores: [0.99048913 0.98505435 0.99183673 0.99183673 0.99455782 0.99183673\n",
      " 0.99591837 0.99047619 0.99047619 0.99319728]\n",
      "Cross Validation Mean is 0.9915679532682639\n"
     ]
    }
   ],
   "source": [
    "# 시드 설정하기\n",
    "seed = 21401\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.permutation(len(train_data))\n",
    "shuffled_train_data = train_data.values[shuffled_indices]\n",
    "shuffled_train_target = train_target[shuffled_indices]\n",
    "\n",
    "# 모델 초기화\n",
    "logistic_regression_classifier = LogisticRegression(solver=\"liblinear\", random_state=12300)\n",
    "random_forest_classifier = RandomForestClassifier(bootstrap=False, n_estimators=120, max_depth=30, random_state=9636, n_jobs=-1)\n",
    "svm_classifier = SVC(C=1, gamma='auto', probability=True, random_state=246, kernel=\"linear\")\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('lr', logistic_regression_classifier), ('rf', random_forest_classifier), ('svc', svm_classifier)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 교차 검증 수행\n",
    "cross_val_scores = cross_val_score(voting_classifier, shuffled_train_data, shuffled_train_target, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Cross Validation Scores: {cross_val_scores}\")\n",
    "print(f\"Cross Validation Mean is {np.mean(cross_val_scores)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최종 값:0.9915679532682639"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시드 설정하기\n",
    "seed = 21401\n",
    "\n",
    "# 데이터 섞기\n",
    "np.random.seed(seed)\n",
    "shuffled_indices = np.random.permutation(len(train_data))\n",
    "shuffled_train_data = train_data.values[shuffled_indices]\n",
    "shuffled_train_target = train_target[shuffled_indices]\n",
    "\n",
    "# 모델 초기화\n",
    "logistic_regression_classifier = LogisticRegression(solver=\"liblinear\", random_state=12300)\n",
    "random_forest_classifier = RandomForestClassifier(bootstrap=False, n_estimators=120, max_depth=30, random_state=9636, n_jobs=-1)\n",
    "svm_classifier = SVC(C=1, gamma='auto', probability=True, random_state=246, kernel=\"linear\")\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('lr', logistic_regression_classifier), ('rf', random_forest_classifier), ('svc', svm_classifier)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 교차 검증 수행\n",
    "cross_val_scores = cross_val_score(voting_classifier, shuffled_train_data, shuffled_train_target, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "print(f\"Cross Validation Scores: {cross_val_scores}\")\n",
    "print(f\"Cross Validation Mean is {np.mean(cross_val_scores)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
